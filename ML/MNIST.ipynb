{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDxGYC_yqTq"
      },
      "source": [
        "# SBU CSE 352 - HW 4 - Machine Learning From Scratch\n",
        "\n",
        "\n",
        "Name: Cody Lam\n",
        "\n",
        "I understand that my submission needs to be my own work: C.L.\n",
        "\n",
        "I understand that ChatGPT / Copilot / other AI tools are not allowed: C.L.\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: 100\n",
        "\n",
        "1. Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Only use standard packages (numpy and built-in packages like random). Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "  **Important:** Do not use scikit-learn or other packages with ML built in. The point of this is to be a learning exercise. Using linear algebra from numpy is okay (things like matrix operations or pseudoinverse, for example, but not lstsq).\n",
        "\n",
        "2. Your notebook needs to be formatted professionally.\n",
        "    - Add additional markdown blocks for your description, comments in the code, add tables and use matplotlib to produce charts where appropriate\n",
        "    - Do not show debugging output or include an excessive amount of output.\n",
        "    - Check that your PDF file is readable. For example, long lines are cut off in the PDF file. You don't have control over page breaks, so do not worry about these.\n",
        "3. Document your code. Add a short discussion of how your implementation works and your design choices.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement several machine learning algorithms and evaluate their accuracy. This will be done for a downscaled version of the MNIST digit recognition dataset.\n",
        "\n",
        "**Like in real life, some of the tasks you will be asked to do may not be possible, at least directly. In these cases, your job is to figure out why it won't work and either propose a fix (best), or provide a clear explanation why it won't work.**\n",
        "\n",
        "For example, if the problem says to do k-nearest neighbors with a dataset of a billion points, this could require too much time to do each classification so it's infeasible to evaluate its test accuracy. In this case, you could suggest randomly downsample the data to a more manageable size, which will speed things up by may lose some accuracy. In your answer, then, you should describe the problem and how you solved it and the trade-offs.\n",
        "\n",
        "# Data\n",
        "First the code below ensures you have access to the training data (a subset of the MNIST images), consisting of 100 handwritten images of each digit."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First download the repo and change the directory to be the one where the dependencies are.\n",
        "# You should only need to do this once per session. If you want to reset, do Runtime -> Disconnect and Delete Runtime\n",
        "# You can always do !pwd to see the current working directory and !ls to list current files.\n",
        "!git clone https://github.com/stanleybak/CS7320-AI.git\n",
        "%cd CS7320-AI/ML\n",
        "!ls"
      ],
      "metadata": {
        "id": "dTw87RlBzTOi",
        "outputId": "4cf9cd22-a72e-4e61-b351-53e0bad4aa23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CS7320-AI' already exists and is not an empty directory.\n",
            "/content/CS7320-AI/ML\n",
            "line_fitting.ipynb\tML_for_tictactoe.ipynb\t\t  README.md\n",
            "mini-mnist-1000.pickle\tML_for_tictactoe_self_play.ipynb\n",
            "ML_example.ipynb\tMNIST.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ny3IAxVAyqTs",
        "outputId": "859a0158-1f28-4b2d-94b9-e3d8f580afc7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABUFJREFUeJzt3U0obGEcx/EhUhY0s2MhSjYsZClh4SUTWSmFjGQplsrWWtlQysZezRDSlJTsZ2FrNRZD2VDe465vz//cZowz9/zO+X6W/547zr1976nzYp6q7+/v7xggpvp/HwDwE4QLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSTXFLqyqqvLzOIBYLBaLFfsglzMuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBX9FUxR09HRYc5ra2udWX9/v7l2e3vbmX19fZV3YCXKZDLObHp62lz7/v7u9+H8Gs64kES4kES4kES4kES4kFRV7JaoYfhi587OTnOeSqWc2dTUlLm2utr9v97c3Gyutf7NgrAD7f7+vjlfXV11Zo+Pjz4fzd/4YmeEGuFCEuFCEuFCUqQuzg4PD815Mpn05ecF9eLMy8DAgDO7urqq6DFwcYZQI1xIIlxIIlxIIlxIitSL5Nls1pyXclfh/v7eme3t7ZlrrcfDpbxI3tvba86tq/+o4YwLSYQLSYQLSYQLSZF65FtTY1+LNjU1Ff0ZHx8fzqxQKPz4mP6loaHBnF9fXzszr3eCLel02pzPzMw4s7e3t6I/9zfwyBehRriQRLiQRLiQRLiQFKlHvp+fn+Y8n89X+EiKMzo6as7j8XhZn3t7e2vOK30HoRyccSGJcCGJcCGJcCEpUo98g8z6suWlpSVzbbnv4yYSCXNe6a9bsvDIF6FGuJBEuJBEuJBEuJAUqUe+lWa9mL22tmaubW9vd2bW1lSlyuVyzsx6GV4NZ1xIIlxIIlxIIlxIitTFWWtrqzmfm5tzZkNDQ2X/vL6+Pmf2G1/sbD2a9broOzk5cWYvLy9lH8P/xhkXkggXkggXkggXkggXkkL7InlXV5cz89ouqqWlxZdj8Gu7qOPjY2c2OTlZ9ucGAS+SI9QIF5IIF5IIF5Ii9cjX6wLTrwvPcnfd8TI+Pu7MxsbGzLWnp6dl/7wg4owLSYQLSYQLSYQLSYQLSaG9q2BtqTQ4OGiunZ2ddWZnZ2fm2tfX17KOy8vi4qIzW15e9uVnhQFnXEgiXEgiXEgiXEgK7fu4ahobG53Zw8ND0X9+YmLCnKs98uV9XIQa4UIS4UIS4UIS4UJSaB/5qvHatxc2zriQRLiQRLiQRLiQJHVxZu1CMzIyYq49Pz93ZkH4QuOFhQVzvrW1VeEj0cYZF5IIF5IIF5IIF5IIF5ICeVfB2mYpFovF1tfXndnw8LC5tq2tzZnl8/nyDsxDIpEw58lk0pltbm6aa+vr64v+edbdEb9++zioOONCEuFCEuFCEuFCUiB/yzeXy5lzaycdLzs7O87s6enpp4f0T14XiD09Pc6slF13Li4uzLn1dzs4OCj6c4OM3/JFqBEuJBEuJBEuJBEuJIX2rkIQWP9md3d35tqjoyNntrKyYq4N8+Nd7iog1AgXkggXkggXkgJ5cdbd3W3OrV1o5ufnfT6av93c3Diz5+dnc+3l5aUz293dNddauwRFERdnCDXChSTChSTChSTChaRA3lXwUldX58xSqZS5dmNjw5nF43FzbTqddmbZbNZcm8lknFmhUDDXonTcVUCoES4kES4kES4kSV2cIfy4OEOoES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kFb2XbynbHAF+44wLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSX8AQl0xL3R5PJ4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# if the below fails to open, then the data file is not in the current working directory (see above code block)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "im3 = data['images'][300] # 100 images of each digit\n",
        "plt.figure(figsize=(2, 2))  # Adjust size as needed\n",
        "plt.imshow(im3, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzts6NT5yqTt"
      },
      "source": [
        "# Downscaling Images\n",
        "\n",
        "MNIST images are originally 28x28. We will train our models not just on the original images, but also on downscaled images with the following sizes: 14x14, 7x7, 4x4, 2x2. The next code block shows one way to do downscaling. As you can tell from the output, we cannot expect our model's accuracy will be too high on lower resolution versions, although it's unclear how much better you can do than random chance, which should have a 10% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "2wTIXhvGyqTt",
        "outputId": "f2dac135-a871-4042-d1c1-d0dbc0a95083"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to downscale an image to different sizes\n",
        "def downscale_image(image, downscaled_size):\n",
        "    block_size = 28 // downscaled_size\n",
        "    downscaled = np.zeros((downscaled_size, downscaled_size))\n",
        "    for i in range(downscaled_size):\n",
        "        for j in range(downscaled_size):\n",
        "            # Calculate the average for each block\n",
        "            block = image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
        "            downscaled[i, j] = np.mean(block)\n",
        "    return downscaled\n",
        "\n",
        "# Load the dataset (assuming this file is in your working directory)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "images = data['images']  # a list of 1000 numpy image matrices\n",
        "labels = data['labels']  # a list of 1000 integer labels\n",
        "\n",
        "# Select 3 \"random\" indices from the dataset\n",
        "random_indices = [300, 500, 200]\n",
        "\n",
        "# Downscale the images to multiple sizes and display them\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "for index in random_indices:\n",
        "    fig, axs = plt.subplots(1, len(sizes), figsize=(10, 2))\n",
        "    for ax, size in zip(axs, sizes):\n",
        "        downscaled_image = downscale_image(images[index], size)\n",
        "        ax.imshow(downscaled_image, cmap='gray', vmin=0, vmax=255)\n",
        "        ax.set_title(f'Size {size}x{size}')\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YePL7s9NyqTw"
      },
      "source": [
        "---\n",
        "# Tasks\n",
        "\n",
        "Your data contains 100 images in each class. When training models, use 80% of training, 10% for validation and 10% for testing. Make sure the data is balanced in each class when splitting.\n",
        "\n",
        "---\n",
        "## Task 1: Linear Classifier [20 points]\n",
        "\n",
        "First, implement a linear classifier. The simplest way to do this is to adapt linear regression approaches that we learned about in class, where the output is a real number. For classification, we can let one category be an output of 1.0 and the other -1.0. Then, after the classifier is trained we can use the sign of the output to determine the predicted class.\n",
        "\n",
        "However, since in MNIST there are multiple classes (10 digits, not just 2), we need to adapt the approach further. We will try both of the following two popular strategies: One-vs-Rest (OvR) and One-vs-One (OvO).\n",
        "\n",
        "**One-vs-Rest (OvR)** is a strategy for using binary classification algorithms for multiclass problems. In this approach, a separate binary classifier is trained for each class, which predicts whether an instance belongs to that class or not, making it the 'one' against all other classes (the 'rest'). For a new input instance, compute the output of all classifiers. The predicted class is the one whose corresponding classifier gives the highest output value.\n",
        "\n",
        "**One-vs-One (OvO)** is another strategy where a binary classifier is trained for every pair of classes. If there are N classes, you will train N(N−1)/2 classifiers. For a new input, evaluate it using all N(N−1)/2​ classifiers. Count the number of times each class is predicted over all binary classifications. The class with the highest count is selected as the final prediction.\n",
        "\n",
        "### Report Results\n",
        "Report the test accuracy for OvR and OvO, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2. A table may be helpful. Also report any interesting observations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Organize the data based on the digits 0-9\n",
        "def organize_data(images, labels):\n",
        "  images_by_digit = {i :[] for i in range(10)}\n",
        "  for image, label in zip(images, labels):\n",
        "    images_by_digit[label].append(image)\n",
        "  return images_by_digit\n",
        "\n",
        "# Now the data is organized by the class, or digits\n",
        "class_data = organize_data(images, labels)\n",
        "\n",
        "# Split the data into train/val/test (80/10/10) for balance\n",
        "def split_data(class_data):\n",
        "  train_images, train_labels = [], [] # training set\n",
        "  val_images, val_labels = [], [] # validation set\n",
        "  test_images, test_labels = [], [] # test set\n",
        "\n",
        "  # Go through the data, label (0-9), images (list of images)\n",
        "  for label, images in class_data.items():\n",
        "    # So there are no bias results\n",
        "    random.shuffle(images)\n",
        "    n = len(images)\n",
        "    train_end = int(0.8*n) # Index where the training data ends\n",
        "    val_end = int(0.9*n) # index where the validation ends\n",
        "\n",
        "    train_images.extend(images[:train_end]) # Adds 80% of images in training set\n",
        "    train_labels.extend([label]*train_end) # Adds train_end copies of the label\n",
        "\n",
        "    val_images.extend(images[train_end:val_end]) # Add the next 10% for validation\n",
        "    val_labels.extend([label]*(val_end - train_end)) # Add the corresponding labels\n",
        "\n",
        "    test_images.extend(images[val_end:]) # Add the remaining 10% of images for testing\n",
        "    test_labels.extend([label]*(n - val_end)) # Corresponding labels\n",
        "\n",
        "  return (np.array(train_images), np.array(train_labels),\n",
        "        np.array(val_images), np.array(val_labels),\n",
        "        np.array(test_images), np.array(test_labels))\n",
        "\n",
        "# Preprocess the data for different sizes\n",
        "def preprocess_data(size):\n",
        "  downscaled_class_data = {lbl: [downscale_image(img, size) for img in imgs] for lbl, imgs in class_data.items()}\n",
        "  return split_data(downscaled_class_data)\n",
        "\n",
        "# Linear regression Model\n",
        "def linear_regression(x_train, y_train):\n",
        "  x_bias = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
        "  y = y_train.reshape(-1, 1)\n",
        "  psuedo_inverse = np.linalg.pinv(x_bias)\n",
        "  w = psuedo_inverse @ y\n",
        "  return w[:-1].flatten(), w[-1, 0]\n",
        "\n",
        "# Flatten images to 1D\n",
        "def flatten_images(images):\n",
        "    n_samples = images.shape[0]\n",
        "    return images.reshape((n_samples, -1))\n",
        "\n",
        "# One-vs-Rest (OvR)\n",
        "def training_ovr(x_train, y_train):\n",
        "  classifiers = {}\n",
        "  for i in range(10):\n",
        "    y_binary = np.where(y_train == i, 1, -1)\n",
        "    w, b = linear_regression(x_train, y_binary)\n",
        "    classifiers[i] = (w, b)\n",
        "  return classifiers\n",
        "\n",
        "# After training the data using OvR, return its predictions\n",
        "def predict_ovr(x_test, classifiers):\n",
        "  predictions = []\n",
        "  for i, (w,b) in classifiers.items():\n",
        "    score = x_test @ w + b\n",
        "    predictions.append(score)\n",
        "  predictions = np.array(predictions)\n",
        "  preds = np.argmax(predictions, axis=0)\n",
        "  return preds\n",
        "\n",
        "# One-vs-one (OvO)\n",
        "def training_ovo(x_train, y_train):\n",
        "  classifiers = {}\n",
        "  for i in range(10):\n",
        "    for j in range(i+1, 10):\n",
        "      idx = np.where((y_train == i) | (y_train == j))[0]\n",
        "      x_train_i = x_train[idx]\n",
        "      y_train_i = np.where(y_train[idx] == i, 1, -1)\n",
        "      w, b = linear_regression(x_train_i, y_train_i)\n",
        "      classifiers[(i, j)] = (w, b)\n",
        "  return classifiers\n",
        "\n",
        "# After training the data using OvO, return its predictions\n",
        "def predict_ovo(x_test, classifiers):\n",
        "  votes = np.zeros((x_test.shape[0], 10))\n",
        "  for (i, j), (w, b) in classifiers.items():\n",
        "    preds = np.sign((x_test @ w + b))\n",
        "    for index, pred in enumerate(preds):\n",
        "      if pred > 0:\n",
        "          votes[index, i] += 1\n",
        "      else:\n",
        "          votes[index, j] += 1\n",
        "  predictions = np.argmax(votes, axis=1)\n",
        "  return predictions\n",
        "\n",
        "# Experiment and Results\n",
        "sizes = [28, 14, 7, 4, 2] # Downscale sizes\n",
        "results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten all the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  val_x_flat = flatten_images(val_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  # Using OvR\n",
        "  ovr_classifiers = training_ovr(train_x_flat, train_y)\n",
        "  ovr_preds = predict_ovr(test_x_flat, ovr_classifiers)\n",
        "\n",
        "  # Using OvO\n",
        "  ovo_classifiers = training_ovo(train_x_flat, train_y)\n",
        "  ovo_preds = predict_ovo(test_x_flat, ovo_classifiers)\n",
        "\n",
        "  # Calculate accuracy\n",
        "  ovr_accuracy = np.mean(ovr_preds == test_y)\n",
        "  ovo_accuracy = np.mean(ovo_preds == test_y)\n",
        "  results.append((size, ovr_accuracy, ovo_accuracy))\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Size\", \"OvR Accuracy\", \"OvO Accuracy\"])\n",
        "results_df"
      ],
      "metadata": {
        "id": "ueSohSbyCljy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "85abe1ac-88cd-4b59-e076-b214f7e9daf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  OvR Accuracy  OvO Accuracy\n",
              "0    28          0.54          0.79\n",
              "1    14          0.38          0.29\n",
              "2     7          0.13          0.14\n",
              "3     4          0.14          0.10\n",
              "4     2          0.06          0.04"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-329d7df3-6a66-4ed0-9673-dfd91d5f3998\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>OvR Accuracy</th>\n",
              "      <th>OvO Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-329d7df3-6a66-4ed0-9673-dfd91d5f3998')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-329d7df3-6a66-4ed0-9673-dfd91d5f3998 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-329d7df3-6a66-4ed0-9673-dfd91d5f3998');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ac257346-133d-42d3-b369-f41528303104\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac257346-133d-42d3-b369-f41528303104')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ac257346-133d-42d3-b369-f41528303104 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f946a16c-7372-4a92-8a72-59d06af835f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f946a16c-7372-4a92-8a72-59d06af835f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OvR Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20223748416156684,\n        \"min\": 0.06,\n        \"max\": 0.54,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.38,\n          0.06,\n          0.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OvO Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3039243326882532,\n        \"min\": 0.04,\n        \"max\": 0.79,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.29,\n          0.04,\n          0.14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6z07BdyqTw"
      },
      "source": [
        "---\n",
        "## Task 2: Data Augmentation [20 points]\n",
        "\n",
        "Your boss was unhappy with the test accuracy, especially of your 2x2 image classifier, and has made some suggestions. The problem, according to your boss, is that there is not enough data in each input $x$. You are told to augment the data with derived features in order to help the classifier.\n",
        "\n",
        "Specifically, given an input $x$, create additional attributes by computing all of the data up to powers of two. For example, in the 2x2 case your example $x$ consists of four pixel values $x_0$, $x_1$, $x_2$, and $x_3$. Your new input data would have:\n",
        "\n",
        "* all power of zero: 1 (constant)\n",
        "* all powers of one: $x_0$, $x_1$, $x_2$, $x_3$\n",
        "* all powers of two:\n",
        "\n",
        "  $x_0^2$, $x_0 x_1$, $x_0 x_2$, $x_0 x_3$,\n",
        "  \n",
        "  $x_1^2$, $x_1 x_2$, $ x_1 x_3$,\n",
        "  \n",
        "  $x_2^2$, $x_2 x_3$,\n",
        "  \n",
        "  $x_3^2$\n",
        "\n",
        "The data would have 15 values, which has the potential to learn nonlinear relationships between the original inputs, which was not possible before.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Report the test accuracy for OvR only, with the data augmentation approach, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2 (again, perhaps incorporating a table). Report any interesting results or observations.\n",
        "\n",
        "Also, explain to your boss what the danger is of looking at a model's final test accuracy and then suggesting changes to improve it. What should be done instead, if you know you will consider different types of models or hyperparameters in the same model class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCvHIrBwyqTw"
      },
      "outputs": [],
      "source": [
        "# Your answer goes here\n",
        "def augment_images(data):\n",
        "    n_samples, n_features = data.shape\n",
        "    augmented_data = [np.ones((n_samples, 1))] # Power of zero: 1 (constant)\n",
        "\n",
        "    # Power of one:\n",
        "    augmented_data.append(data)\n",
        "\n",
        "    # Power of two:\n",
        "    for i in range(n_features):\n",
        "        for j in range(i, n_features):\n",
        "            augmented_data.append(data[:, i] * data[:, j].reshape(-1, 1))\n",
        "\n",
        "    # Concatenate all the features horizontally\n",
        "    augmented_data = np.hstack(augmented_data)\n",
        "    return augmented_data\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2] # Downscale sizes\n",
        "augmented_results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  val_x_flat = flatten_images(val_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  # Aumentation of the data\n",
        "  train_x_augmented = augment_images(train_x_flat)\n",
        "  val_x_augmented = augment_images(val_x_flat)\n",
        "  test_x_augmented = augment_images(test_x_flat)\n",
        "\n",
        "  # Train the OvR only\n",
        "  ovr_classifiers = training_ovr(train_x_augmented, train_y)\n",
        "  ovr_preds = predict_ovr(test_x_augmented, ovr_classifiers)\n",
        "  ovr_accuracy = np.mean(ovr_preds == test_y)\n",
        "\n",
        "  augmented_results.append((size, ovr_accuracy))\n",
        "\n",
        "augmented_results_df = pd.DataFrame(augmented_results, columns=[\"Size\", \"OvR Accuracy\"])\n",
        "augmented_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "The danger of looking at a model's final test accurancy and then suggesting changes to improve it is that is allows the model see what should be unseen data, resulting in overfitting. Instead, you should only test using the validation set when deciding different types of models and deciding the hyperparameters."
      ],
      "metadata": {
        "id": "5dTSqmI0CbsA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz7hMCAkyqTw"
      },
      "source": [
        "---\n",
        "## Task 3: k-Nearest Neighbors Classifier [20 points]\n",
        "\n",
        "Your boss is still unhappy with the results (and still ignoring your advice about not using test data accuracy for model decisions).\n",
        "\n",
        "Next, you are to use the k-nearest neighbors approach to build a classifier for our data. Since we have multiple classes, the one that gets selected can be based on a plurality vote of the $k$ closest samples (whichever category is most frequent). If there are ties, select the class based on the sum of the distances from the test point. For example, if $k=5$, and the closest 5 samples have two pictures that are from category \"1\" and two pictures that are from category \"7\", then you choose the output by computing the sum of the distance from the test point and the two \"5\" samples, as well as the sum of distances from the test point to the two \"7\" samples, and then outputting the class with the smaller total distance.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "For each image size, exhaustively explore different values of $k$ up to 50. Report the best test accuracy. Report the average time taken to do a lookup with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7pGs5acyqTw",
        "outputId": "fea87a7f-2e06-4cc1-9528-8509dbfb2a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Size  Best K  Best Accuracy  Best Time\n",
              "0    28       1           0.88   0.169273\n",
              "1    14       1           0.91   0.047154\n",
              "2     7       1           0.88   0.026672\n",
              "3     4       1           0.76   0.012067\n",
              "4     2      19           0.49   0.019635"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a48c780-1e45-49ad-803e-6528a5b1471f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Best K</th>\n",
              "      <th>Best Accuracy</th>\n",
              "      <th>Best Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.169273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.047154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.026672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.012067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.019635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a48c780-1e45-49ad-803e-6528a5b1471f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a48c780-1e45-49ad-803e-6528a5b1471f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a48c780-1e45-49ad-803e-6528a5b1471f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5bd8f22-f354-45df-8c40-336a71224623\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5bd8f22-f354-45df-8c40-336a71224623')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5bd8f22-f354-45df-8c40-336a71224623 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0ad97b65-9aac-4006-b79d-b773a3561e27\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('knn_results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0ad97b65-9aac-4006-b79d-b773a3561e27 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('knn_results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "knn_results_df",
              "summary": "{\n  \"name\": \"knn_results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 2,\n        \"max\": 28,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 19,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          19,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17415510328439993,\n        \"min\": 0.49,\n        \"max\": 0.91,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.91,\n          0.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0652232030449352,\n        \"min\": 0.012067317962646484,\n        \"max\": 0.16927313804626465,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.04715442657470703,\n          0.01963496208190918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Function to compute the Euclidean distance\n",
        "def euclidean_distance(x1, x2):\n",
        "  # return np.sqrt(np.sum((x1 - x2)**2))\n",
        "  return np.linalg.norm(x1 - x2)\n",
        "\n",
        "# Function to predict a single test sample\n",
        "def knn_predict(train_x, labels, x_test, k):\n",
        "  # Compute all the distances\n",
        "  distances = np.linalg.norm(train_x - x_test, axis=1)\n",
        "  # Get the k nearest neighbor indices\n",
        "  nearest_indices = np.argsort(distances)[:k]\n",
        "  nearest_labels = labels[nearest_indices]\n",
        "\n",
        "  # Count the occurrences\n",
        "  unique, counts = np.unique(nearest_labels, return_counts=True)\n",
        "  max_count = np.max(counts)\n",
        "  max_indices = np.where(counts == max_count)[0]\n",
        "  if len(max_indices) == 1:\n",
        "    return unique[max_indices[0]]\n",
        "  else:\n",
        "      # Ties break into smaller total distances\n",
        "      sums = {}\n",
        "      for label in max_indices:\n",
        "        indices = nearest_indices[nearest_labels == label]\n",
        "        sum = np.sum(distances[indices])\n",
        "        sums[label] = sum\n",
        "      return min(sums, key=sums.get)\n",
        "\n",
        "# The knn classifier\n",
        "def knn_classifier(train_x, train_y, test_x, k):\n",
        "  predictions = []\n",
        "  for x_test in test_x:\n",
        "    prediction = knn_predict(train_x, train_y, x_test, k)\n",
        "    predictions.append(prediction)\n",
        "  return np.array(predictions)\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "knn_results = []\n",
        "\n",
        "for size in sizes:\n",
        "  # Get the training, val and test data based on the sizes\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = preprocess_data(size)\n",
        "\n",
        "  # Flatten the images\n",
        "  train_x_flat = flatten_images(train_x)\n",
        "  test_x_flat = flatten_images(test_x)\n",
        "\n",
        "  best_accuracy = 0\n",
        "  best_k = None\n",
        "  best_time = None\n",
        "\n",
        "  for k in range(1, 51):\n",
        "    start_time = time.time()\n",
        "    preds = knn_classifier(train_x_flat, train_y, test_x_flat, k)\n",
        "    end_time = time.time()\n",
        "    curr_accuracy = np.mean(preds == test_y)\n",
        "\n",
        "    # If the current accuracy in better then best accurancy\n",
        "    if curr_accuracy > best_accuracy:\n",
        "      best_accuracy = curr_accuracy\n",
        "      best_k = k\n",
        "      best_time = end_time - start_time\n",
        "\n",
        "  knn_results.append((size, best_k, best_accuracy,best_time))\n",
        "\n",
        "knn_results_df = pd.DataFrame(knn_results, columns=[\"Size\", \"Best K\", \"Best Accuracy\", \"Best Time\"])\n",
        "knn_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Task 4: Decision Trees [15 Points]\n",
        "\n",
        "Your boss heard that **decision trees**, **regression trees** and **random forests** are popular in machine learning and wants to see how well they will work on the problem. Adapt one of these approaches (you don't have to do all three) in a way that allows it to make reasonable predictions for this domain, and report what you needed to do. Report your results in terms of test accuracy for the different image sizes in a table. If some of your ideas do not work, report what you tried and why not.\n",
        "\n",
        "**Note 1**: As described in class, decision trees work on categorical attributes, so you will need to adapt things, perhaps by choosing thresholds for the continuous variables in some reasonable way. Describe your thought process and what you did.\n",
        "\n",
        "**Note 2**: Do not use ChatGPT to do the thinking for you. Do not use `scikit-learn` or other ML libraries for this task. Using `numpy`, `scipy`, and `pandas` is okay.\n",
        "\n",
        "**Note 3**: For splitting categorical variables in decision trees, recall from the slides that information in an answer when the prior is $ \\langle P_1, \\ldots, P_n \\rangle $ is $H(P_1, \\ldots, P_n) = -\\sum_{i=1}^{n} P_i \\log_2 P_i $. The suggestion was to use entropy to greedily select which attributes to split on.\n",
        "\n",
        "**Note 4**: If you want to try random forests or regression trees, video lectures will be provided in a Brightspace announcements. Feel free to also read the book and seek online resources, but do not copy over existing code.\n"
      ],
      "metadata": {
        "id": "iGMTKFeMR9kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Compute the entropy\n",
        "def entropy(y):\n",
        "  counts = Counter(y)\n",
        "  probabilities = np.array(list(counts.values()) / len(y))\n",
        "  entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
        "  return entropy\n",
        "\n",
        "class DecisionTreeNode:\n",
        "  def __init__(self, depth=0, max_depth=10):\n",
        "    self.depth = depth\n",
        "    self.max_depth = max_depth\n",
        "    self.feature = None\n",
        "    self.threshold = None\n",
        "    self.left = None\n",
        "    self.right = None\n",
        "    self.value = None\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    # Stop Condition\n",
        "    if len(set(y)) == 1:\n",
        "      self.predicted_class = y[0]\n",
        "      return\n",
        "\n",
        "    # If the current depth is greater than the max depth or len of x is zero\n",
        "    if self.depth >= self.max_depth or len(x) == 0:\n",
        "      self.predicted_class = np.bincount(y).argmax() # Set the predicted class\n",
        "      return\n",
        "\n",
        "    # Find the best split\n",
        "    best_gain = -1\n"
      ],
      "metadata": {
        "id": "Mbr8m4BYULsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyN1oAczyqTw"
      },
      "source": [
        "---\n",
        "## Task 5: Neural Networks [25 Points]\n",
        "\n",
        "Next, your boss wants you to try neural networks. Rather than using a library to do the training for you, you will **only** use `pytorch` to perform backpropagation and compute gradients. Using activation functions like `torch.sigmoid` or `torch.softmax` is allowed, as you need to do this for computing gradients. You can write your own high-level neural network class if desired, don't use anything from `pytorch` for that.\n",
        "\n",
        "\n",
        "An example network and how to compute gradients with pytorch is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVYHnm2fyqTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbbd6d3-1316-4fcc-b43d-8218569ba8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Output: tensor([0.5348, 0.2167, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
            "Desired Output: tensor([1., 0., 0.])\n",
            "Initial loss: 0.625852644443512\n",
            "Gradient for weights matrix W1: tensor([[-2.9431e-03, -5.8862e-03, -8.8293e-03],\n",
            "        [ 4.1993e-03,  8.3986e-03,  1.2598e-02],\n",
            "        [-3.0524e-06, -6.1048e-06, -9.1572e-06]])\n",
            "New loss after updating weights and biases: 0.6079817414283752\n"
          ]
        }
      ],
      "source": [
        "# Example of using pytorch to compute gradients and updates weights and biases\n",
        "#\n",
        "# The network consists of:\n",
        "# 1. An input layer with 3 features.\n",
        "# 2. A first hidden layer with 3 neurons. Each neuron in this layer performs a linear transformation\n",
        "#    on the input data using a weight matrix (W1) and a bias vector (b1). This is followed by a sigmoid\n",
        "#    activation function.\n",
        "# 3. A second hidden layer, also with 3 neurons, which processes the output of the first layer. Similar\n",
        "#    to the first layer, it uses a weight matrix (W2) and a bias vector (b2) for linear transformation,\n",
        "#    followed by a softmax activation function. The softmax activation is used here to normalize the\n",
        "#    output of the second layer into a probability distribution over the three classes. This is particularly\n",
        "#    useful for multi-class classification problems.\n",
        "# 4. The network uses cross-entropy as the loss function, which is a common choice for classification tasks\n",
        "#    involving softmax outputs. This loss function compares the predicted probability distribution with the\n",
        "#    true distribution (one-hot encoded) and penalizes the predictions that diverge from the actual labels.\n",
        "#\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# Initialize input, weights, and biases\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "W1 = torch.tensor([[0.1, 0.2, 0.5],\n",
        "                  [-0.1, -0.5, -1.1],\n",
        "                  [0, 7.5, -1.1]], requires_grad=True)\n",
        "b1 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "W2 = torch.tensor([[0.1, -0.3, 0.4],\n",
        "                  [0.2, 0.4, -0.6],\n",
        "                  [-0.1, 0.5, -0.2]], requires_grad=True)\n",
        "b2 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "# Target output\n",
        "y_true = torch.tensor([1.0, 0.0, 0.0])\n",
        "\n",
        "# Forward pass through first layer\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "\n",
        "# Forward pass through second layer\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "print(\"Initial Output:\", a2)\n",
        "print(\"Desired Output:\", y_true)\n",
        "\n",
        "# Compute loss (Cross-entropy): https://en.wikipedia.org/wiki/Cross-entropy\n",
        "loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"Initial loss:\", loss.item())\n",
        "\n",
        "# Backpropagation\n",
        "loss.backward()\n",
        "\n",
        "# you can print out gradient for each element now\n",
        "print(\"Gradient for weights matrix W1:\", W1.grad)\n",
        "\n",
        "# Update weights and biases based on gradient (should reduce loss)\n",
        "learning_rate = 0.02\n",
        "\n",
        "# the no_grad() environment is needed to indicate that the computation should not\n",
        "# be part of the gradient computation\n",
        "with torch.no_grad():\n",
        "    W1 -= learning_rate * W1.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    W2 -= learning_rate * W2.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "\n",
        "# After the update, clear the gradients (in case we want to compute them again later)\n",
        "W1.grad.zero_()\n",
        "b1.grad.zero_()\n",
        "W2.grad.zero_()\n",
        "b2.grad.zero_()\n",
        "\n",
        "# Forward pass with updated weights and biases\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "# Compute new loss\n",
        "new_loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"New loss after updating weights and biases:\", new_loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above updates the parameters based on a single piece of data, but often multiple inputs are used and their gradient is averaged when updating a model.\n",
        "\n",
        "Your task is to write the training code for the different neural network architectures proposed and report accuracy. Start with all random parameters between -1 and 1. Training should stop when the accuracy, as measured on the validation data, no longer appears to be improving. You can plot the validation data accuracy over time to ensure this looks correct. If this takes too long but it appears the model is still improving in accuracy, consider increasing the learning rate (start with 0.02 as in the example).\n",
        "\n",
        "For the gradient, you are to compute the gradient over the full set of training data, and then average them together before you update. Then, repeat with mini-batches of size 100, with 10 random samples from each class. This should update the model weights faster, but may require more updates to get the accuracy down.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Provide at least one plot of your validation data accuracy going down over time as training progresses. What was the condition you decided to use to detect if training should stop? How many updates were needed in the case of your plot?\n",
        "\n",
        "\n",
        "Create a table where each row corresponds to one model and training method (mini-batch or full). Use the 7x7 version of the data (49-dimensional inputs). You are to explore the following models: the number of hidden layers can be varied between 2 and 4. Each layer's size can be 16, 32, or 64 neurons (all hidden layers have the same number of neurons). Explore three different activation functions for the network, ReLU (`torch.relu`), arctan (`torch.atan`), and sigmoid (`torch.sigmoid`). After the final layer, use a softmax rather than the normal network activation function, to ensure all outputs are between 0 and 1. There should be 10 outputs, one for each class in the MNIST data.\n",
        "\n",
        "In the table, report the architecture, training time, number of model updates and test accuracy. What is the best architecture? Did mini-batches help with anything? Report any other interesting observations.\n",
        "\n"
      ],
      "metadata": {
        "id": "hddWtjp7bHvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The architecture of a neural network\n",
        "class NeuralNetwork:\n",
        "  def __init__(self, input_size, hidden_size, num_layers, activation_func):\n",
        "    self.num_layers = num_layers\n",
        "    self.activation_func = activation_func # Exploring the three different functions\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "\n",
        "    # Initialize the weights and biases\n",
        "    last_size = input_size\n",
        "    for _ in range(num_layers):\n",
        "      # Empty weight\n",
        "      W = torch.empty((hidden_size, last_size), requires_grad=True).uniform_(-1, 1)\n",
        "      b = torch.empty((hidden_size, 1), requires_grad=True).uniform_(-1, 1)\n",
        "      self.weights.append(W)\n",
        "      self.biases.append(b)\n",
        "      last_size = hidden_size\n",
        "\n",
        "    # Output layer\n",
        "    W = torch.empty((10, hidden_size), requires_grad=True).uniform_(-1, 1)\n",
        "    b = torch.empty((10, 1), requires_grad=True).uniform_(-1, 1)\n",
        "    self.weights.append(W)\n",
        "    self.biases.append(b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    for i in range(self.num_layers):\n",
        "      out = self.activation_func(torch.matmul(self.weights[i], out) + self.biases[i])\n",
        "    out = torch.softmax(torch.matmul(self.weights[-1], out) + self.biases[-1], dim=0)\n",
        "    return out\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.weights + self.biases\n",
        "\n",
        "  # Stop when the accuracy no longer appears to be improving\n",
        "  def train(self, x_train, y_train, x_val, y_val, learning_rate=0.02, batch_size=None, max_epochs=500):\n",
        "    train_x = torch.tensor(x_train, dtype=torch.float32)\n",
        "    train_y = torch.tensor(y_train, dtype=torch.long)\n",
        "    val_x = torch.tensor(x_val, dtype=torch.float32)\n",
        "    val_y = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(max_epochs):\n",
        "      # Use a full batch size\n",
        "      if batch_size is None:\n",
        "        x_batch = train_x\n",
        "        y_batch = train_y\n",
        "      else:\n",
        "        # Use a mini-batch size\n",
        "        idx = []\n",
        "        for c in range(10):\n",
        "          idx_c = torch.where(train_y == c)[0]\n",
        "          idx_c_sample = idx_c[torch.randperm(len(idx_c)[:10])]\n",
        "          idx.append(idx_c_sample)\n",
        "        idx = torch.cat(idx)\n",
        "        x_batch = train_x[idx]\n",
        "        y_batch = train_y[idx]\n",
        "\n",
        "      # Forwards\n",
        "      preds = []\n",
        "      loss = 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GxJf4LR8f54p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}